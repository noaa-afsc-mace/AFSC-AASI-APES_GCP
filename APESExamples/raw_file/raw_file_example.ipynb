{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83bf3ace-3ed4-4318-adce-bc6cc125299b",
   "metadata": {},
   "source": [
    "# Running APES on .raw files\n",
    "\n",
    "This notebook contains an acoustic-only example of the Automatic Probabilistic Echo Solving (APES) approach. To further generalize the applications, this notebook applies the Bayesian inversion model using the PobabilisticEchoInversion package in Julia (see [Urmy et al., 2023](https://doi.org/10.1093/icesjms/fsad102)) to Kongsberg Simrad .raw files  and associated calibrations ingested using the pyEcholab python library.\n",
    "\n",
    "### 1. User-defined inputs\n",
    "Provide the location of the raw file(s) and associated Simrad .xml calibration files. Here, an example file and associated calibrations are provided in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394f5ad-147d-42fa-87cb-64eaaef9cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawFileName = \"data/raw/DY2408-D20240611-T161838cw.raw\"\n",
    "calFileName = \"data/cal/\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a2621-a918-4f1c-a35e-66bb683e13af",
   "metadata": {},
   "source": [
    "### 2. Set up environment\n",
    " - Activate and load Julia environment and associated packages\n",
    " - The `ProbabilisticEchoInversion` implementation of APES was designed for distributed computing, so workers are initilized\n",
    " - Initialize `pyEcholabReader`, the associated python module used for data ingestion and initial processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629aa218-b078-4018-98a1-0371d858102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Activate the environment\n",
    "Pkg.activate() \n",
    "# This will need to be run once if these packages are not already installed in the environment (this will take a while)\n",
    "#Pkg.add.([\"PythonCall\",\"CSV\", \"DataFrames\", \"DataFramesMeta\", \"Plots\",\"Glob\",\"DimensionalData\",\"ProbabilisticEchoInversion\",\"Distributed\",\"SDWBA\",\"UnderwaterAcoustics\"])\n",
    "\n",
    "# Set up the environment variables used by PythonCall\n",
    "ENV[\"JULIA_CONDAPKG_BACKEND\"] = \"Null\" \n",
    "ENV[\"JULIA_PYTHONCALL_EXE\"] = \"/opt/conda/bin/python\" # This shouldn't change?\n",
    "\n",
    "# Load the required Julia packages\n",
    "using PythonCall\n",
    "using CSV, DataFrames, Plots\n",
    "using Glob\n",
    "using DimensionalData, DimensionalData.Dimensions\n",
    "using DataFramesMeta\n",
    "using ProbabilisticEchoInversion\n",
    "using Distributed\n",
    "\n",
    "# Set up distributed computing\n",
    "addprocs(topology=:master_worker,exeflags=\"--project=$(Base.active_project())\")\n",
    "\n",
    "# Load the required Julia packages on all workers\n",
    "@everywhere begin # on all of our workers....\n",
    "    using ProbabilisticEchoInversion\n",
    "    using SDWBA\n",
    "    include(joinpath(@__DIR__, \"../src/bubbles.jl\"))\n",
    "    using DimensionalData\n",
    "    using DimensionalData.Dimensions: @dim, YDim, XDim\n",
    "    using DataFrames\n",
    "end\n",
    "\n",
    "\n",
    "# Set the path for the python envieonment to the current directory\n",
    "pyimport(\"sys\").path.append(pwd())\n",
    "\n",
    "# Import the pyEcholabReader module from the current directory\n",
    "pyEcholabReader = pyimport(\"pyEcholabReader\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc1169-0a2b-440f-a154-cab41476b86a",
   "metadata": {},
   "source": [
    "### 3a. Read raw file(s) and conduct integration\n",
    "\n",
    "`pyEcholabReader.integrationTable` returns a dataframe of columns `['interval','layer','frequency','mean_Sv']` containing the integrated volume backscattering strength by interval (horizontal) by layer (vertical). The following input parameters can be provided to modify the integration results:\n",
    " - raw_files (str): Path to raw files or directory containing raw files\n",
    " - cal_file (str): Path to calibration file or directory (optional)\n",
    " - interval_axis (str): Axis to use for integration intervals (default 'ping_number')\n",
    " - interval_length (int): Length of integration intervals (default 50)\n",
    " - layer_axis (str): Axis to use for integration layers (default 'range')\n",
    " - layer_thickness (int): Thickness of integration layers (default 5)\n",
    " - surf_offset (float/int/str): Surface exclusion offset (default 2)\n",
    " - bot_offset (float): Bottom exclusion offset (default 0.5)\n",
    "\n",
    "The interval axes can be specified according to pyEcholab gridding protocol. Note that the returned dataframe is a `Py` datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32bc3d-7586-4c8b-9d0d-a179873333fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigDF = pyEcholabReader.integrationTable(rawFileName,calFileName)\n",
    "print(\"Dataframe data type: $(typeof(bigDF))\")\n",
    "display(bigDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b5491-3a5f-4ed5-883f-3949a4abc331",
   "metadata": {},
   "source": [
    "### 3b. Convert datatype to Julia dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3feeb4d-5f21-4f0f-9e5a-440f9d531afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "function convert_pandas_to_df_float(py_df)\n",
    "    # Convert a pandas DataFrame to a Julia DataFrame, converting numeric columns to Float64\n",
    "\n",
    "    # Get column names\n",
    "    colnames = Symbol.(collect(py_df.columns))\n",
    "    \n",
    "    # Initialize data dictionary\n",
    "    data = Dict{Symbol, Any}()\n",
    "    \n",
    "    # Process each column\n",
    "    for name in py_df.columns\n",
    "        col_data = collect(py_df[name])\n",
    "        \n",
    "        # Check if column appears to be numeric\n",
    "        if all(x -> pyisinstance(x, pybuiltins.float) || \n",
    "                   pyisinstance(x, pybuiltins.int) || \n",
    "                   pyis(x, pybuiltins.None), col_data)\n",
    "            # Convert to Float64, handling None/NaN values\n",
    "            data[Symbol(name)] = [pyis(x, pybuiltins.None) ? NaN : pyconvert(Float64, x) for x in col_data]\n",
    "        else\n",
    "            # Keep as is for non-numeric columns\n",
    "            data[Symbol(name)] = col_data\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return DataFrame(data)\n",
    "end\n",
    "\n",
    "bigDF = convert_pandas_to_df_float(bigDF);\n",
    "\n",
    "print(\"Dataframe data type: $(typeof(bigDF))\")\n",
    "display(first(bigDF,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a5dd4-219e-43fc-8bf1-82f3cddcc114",
   "metadata": {},
   "source": [
    "### 4. Set the dimensions for reformatting the dataframe by frequency\n",
    "\n",
    "We'll confirm this by displaying the echograms of the integrated data by channel (using nominal frequencies of 18, 38, 70, 120, and 200 kHz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86c772-1370-453f-8798-1dbdb44568f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimensions of the data\n",
    "@dim Z YDim \"Layer\" \n",
    "@dim D XDim \"Interval\" \n",
    "\n",
    "# Remake 'echo' including those names\n",
    "echo = unstack_echogram(Main.eval(bigDF), :interval, :layer, :frequency, :mean_Sv, D, Z);\n",
    "print(\"Size of Dimension Layer/Interval/Frequency: $(size(echo))\")\n",
    "\n",
    "# Build and plot the integration data heatmaps\n",
    "echos = [heatmap(echo[F(Near(f))],yflip=true) for f in [18000, 38000,70000,120000,200000]];\n",
    "plot(echos...,size=(900,700),title=[\"18 kHz\" \"38 kHz\" \"70 kHz\" \"120 kHz\" \"200 kHz\"],layout=(3,2),colorbar=true,fmt = :png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa9be4-17cc-4d3c-b112-5dbc557c48cf",
   "metadata": {},
   "source": [
    "### 5. Build reference frequency responses\n",
    "\n",
    "For this simplified example, target strength curves are parameterized and modeled for fish, krill, and jellyfish using the target_strength function in the SDWBA Julia package. The `params` tuple is created to provide priors for use in the model in the next step. In survey implementations, this parameterization occurs using trawl catch data and associated TS relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e722343-b168-47ae-81bd-a56c2b04d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique frequencies\n",
    "freqs = unique(bigDF.frequency)\n",
    "\n",
    "depth = 50.0\n",
    "a = 0.0005\n",
    "δ = 0.5\n",
    "fish = Bubble(a, depth=depth, δ=δ)\n",
    "krill = resize(Models.krill_mcgeehee,0.025)\n",
    "# EBS/GOA average values from Lucca et al. 2021\n",
    "krill.g .= 1.019\n",
    "krill.h .= 1.032\n",
    "\n",
    "ts_fish(freq) = target_strength(fish, freq)\n",
    "ts_krill(freq) = target_strength(krill, freq, 1470)\n",
    "ts_jelly(freq) =  (6e-10*(freq^2) - 0.0002*freq +8.9785)-60.1\n",
    "\n",
    "TS = [ts_fish.(freqs) ts_krill.(freqs) ts_jelly.(freqs)];\n",
    "params = (; TS);\n",
    "\n",
    "plot(freqs/1e3, TS,label=[\"Pollock\" \"Krill\" \"Jelly\"],\n",
    "    xlabel=\"Frequency (kHz)\", marker=:circle,ylabel=\"TS (dB re m⁻²)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e3332-2ba3-4308-af00-ea8fe2e30749",
   "metadata": {},
   "source": [
    "### 6. Run the inversion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee978cc3-1218-4dc8-95eb-14e0d1dc15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    @model function examplemodel(data, params)\n",
    "\n",
    "        nfreq, nspp = size(params.TS) \n",
    "        Σ = exp10.(params.TS ./ 10) # TS is converted to sigma bs\n",
    "\n",
    "        # define priors\n",
    "        logn ~ arraydist(Normal.(zeros(nspp), fill(3, nspp))) # scatterer log-densities\n",
    "        ϵ ~ Exponential(1.0) # observation error variance\n",
    "\n",
    "        # Predict Sv based on scatterer density and TS\n",
    "        n = exp10.(logn)\n",
    "        μ = 10log10.(Σ * n)\n",
    "\n",
    "        # Compare observed to predicted backscatter\n",
    "        #for i in findall(!ismissing, data.backscatter)\n",
    "        #    data.backscatter[i] .~ Normal.(μ, fill(ϵ, nfreq))\n",
    "        #end\n",
    "        data.backscatter .~ Normal.(μ, fill(ϵ, nfreq))\n",
    "    end\n",
    "end\n",
    "\n",
    "# Note, for speed, this examples uses MAPSolver in place of MCMC\n",
    "solution_map = apes(echo, examplemodel, MAPSolver(), params=params);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe5194d-7275-4e56-b7b9-8d8f59336d15",
   "metadata": {},
   "source": [
    "### Model output\n",
    "\n",
    "First the log abundance of each predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb9c7e-f7a1-4538-a1b6-984661cc261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mean = passmissing(mean).(solution_map);\n",
    "post_cv = passmissing(cv).(solution_map);\n",
    "\n",
    "ps = Array{Any}(nothing, size(params.TS)[2])\n",
    "map(1:size(params.TS)[2]) do s\n",
    "    h  =[c[s] for c in post_mean]\n",
    "    ps[s] = heatmap(h,yflip=true,clim=(-4.5,2.5))\n",
    "end\n",
    "plot(ps...,title=[\"Pollock\" \"Krill\" \"Jelly\"],size=(900,700))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c097c-d7df-452b-9d9b-d098405e2aeb",
   "metadata": {},
   "source": [
    "Additionally, we can retrieve the CV by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba908259-807d-453d-8719-1e39ae2b35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_plots = Array{Any}(nothing, size(params.TS)[2])\n",
    "map(1:size(params.TS)[2]) do s\n",
    "    h  =[10^(c[s]) for c in post_cv]\n",
    "    cv_plots[s] = heatmap(h,yflip=true,clim=(0,3),c = :viridis)\n",
    "end\n",
    "\n",
    "plot(cv_plots...,title=[\"Pollock\" \"Krill\" \"Jelly\"],size=(900,700))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
